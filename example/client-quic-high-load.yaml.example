# paqet Client Configuration for High Connection Pressure with QUIC
#
# All buffer, window, and performance settings are now auto-tuned from CPU count
# and RAM at startup — this file is identical to client-quic.yaml.example.
# You no longer need a separate "high-load" config; the defaults are already
# optimized for high bandwidth.  Override individual fields only to fine-tune.
role: "client"

# Logging configuration
log:
  level: "info"  # Use "warn" or "error" at very high load to reduce overhead

# SOCKS5 proxy configuration (client mode)
socks5:
  - listen: "127.0.0.1:1080"    # SOCKS5 proxy listen address
    username: ""                # Optional SOCKS5 authentication
    password: ""                # Optional SOCKS5 authentication

# Network interface settings
network:
  interface: "en0"                          # CHANGE ME: Network interface (en0, eth0, wlan0, etc.)
  # guid: "\Device\NPF_{...}"               # Windows only (Npcap).

  # IPv4 configuration
  ipv4:
    addr: "192.168.1.100:0"                 # CHANGE ME: Local IP (use port 0 for random port)
    router_mac: "aa:bb:cc:dd:ee:ff"         # CHANGE ME: Gateway/router MAC address

  tcp:
    local_flag: ["PA"]                      # Local TCP flags (Push+Ack default)
    remote_flag: ["PA"]                     # Remote TCP flags (Push+Ack default)

# Server connection settings
server:
  addr: "10.0.0.100:9999"  # CHANGE ME: paqet server address and port

# Transport protocol configuration — QUIC
transport:
  protocol: "quic"
  conn: 1           # Number of connections (1-256, default: 1)

  quic:
    # TLS — typically the only setting you need to change.
    insecure_skip_verify: true          # Set true for self-signed certs (testing)
                                        # Set false in production with proper certificates
    # server_name: "example.com"        # Optional: server name for TLS verification

    # All other QUIC settings are auto-tuned.  Override only if needed:
    # max_idle_timeout: 30
    # max_incoming_streams: 5000        # auto: cpus×1250, e.g. 5000 on 4 cores
    # keep_alive_period: 15

# Performance section is fully auto-tuned — only override if needed:
# performance:
#   max_concurrent_streams: 10000       # auto: cpus×2500, e.g. 10000 on 4 cores
#   packet_workers: 4                   # auto: GOMAXPROCS (capped at 64)
#   stream_worker_pool_size: 5000       # auto: cpus×1250
#   tcp_connection_pool_size: 100       # auto: cpus×25
#   tcp_connection_idle_timeout: 90
#   max_retry_attempts: 5
#   retry_initial_backoff_ms: 100
#   retry_max_backoff_ms: 10000

# Additional client-side OS tuning recommendations for high load:
#
# 1. Increase file descriptor limits:
#    ulimit -n 100000
#
# 2. Expand local port range for many concurrent connections:
#    sudo sysctl -w net.ipv4.ip_local_port_range="1024 65535"
#
# 3. Enable TCP fast open:
#    sudo sysctl -w net.ipv4.tcp_fastopen=3
#
# 4. For macOS, increase socket buffer sizes:
#    sudo sysctl -w net.inet.tcp.sendspace=1048576
#    sudo sysctl -w net.inet.tcp.recvspace=1048576
