# paqet Client Configuration for High Connection Pressure with QUIC
# This configuration is optimized for handling many concurrent connections
role: "client"

# Logging configuration
log:
  level: "info"  # Use "warn" or "error" for very high load to reduce overhead

# SOCKS5 proxy configuration (client mode)
socks5:
  - listen: "127.0.0.1:1080"    # SOCKS5 proxy listen address
    username: ""                # Optional SOCKS5 authentication
    password: ""                # Optional SOCKS5 authentication

# Network interface settings
network:
  interface: "en0"                          # CHANGE ME: Network interface (en0, eth0, wlan0, etc.)
  # guid: "\Device\NPF_{...}"               # Windows only (Npcap).

  # IPv4 configuration
  ipv4:
    addr: "192.168.1.100:0"                 # CHANGE ME: Local IP (use port 0 for random port)
    router_mac: "aa:bb:cc:dd:ee:ff"         # CHANGE ME: Gateway/router MAC address

  tcp:
    local_flag: ["PA"]                      # Local TCP flags (Push+Ack default)
    remote_flag: ["PA"]                     # Remote TCP flags (Push+Ack default)

# Server connection settings
server:
  addr: "10.0.0.100:9999"  # CHANGE ME: paqet server address and port

# Transport protocol configuration - QUIC optimized for high load
transport:
  protocol: "quic"  # Using QUIC for high performance under pressure
  conn: 1           # Number of connections (1-256, default: 1)

  # QUIC protocol settings optimized for high connection pressure
  quic:
    # Connection settings - INCREASED FOR HIGH LOAD
    max_idle_timeout: 60                # Increased to 60s to prevent premature disconnections
    max_incoming_streams: 10000         # High limit for concurrent streams on client
    max_incoming_uni_streams: 10000     # High limit for unidirectional streams
    
    # Flow control settings - OPTIMIZED FOR HIGH BANDWIDTH
    # These values balance memory usage with performance
    initial_stream_receive_window: 6291456      # 6 MB
    max_stream_receive_window: 25165824         # 24 MB
    initial_connection_receive_window: 15728640 # 15 MB
    max_connection_receive_window: 62914560     # 60 MB
    
    # Performance settings
    enable_0rtt: true                   # Enable 0-RTT for faster reconnections
    keep_alive_period: 15               # Keep-alive every 15s for better dead connection detection
    
    # TLS settings - Important for QUIC!
    insecure_skip_verify: true          # Set to true for self-signed certs (testing)
                                        # Set to false in production with proper certificates
    # server_name: "example.com"        # Optional: specify server name for TLS verification

# Performance tuning for high connection pressure
performance:
  # CRITICAL: Increase concurrent stream limit for high load
  max_concurrent_streams: 10000         # Allow up to 10k concurrent stream handlers
  
  # Packet processing optimization
  packet_workers: 4                     # Increase based on CPU cores (default: num_cores)
  stream_worker_pool_size: 2000         # Worker pool for stream handling
  
  # TCP connection pooling - NOT typically needed on client, but can help
  enable_connection_pooling: false      # Usually disabled on client
  tcp_connection_pool_size: 100
  tcp_connection_idle_timeout: 90
  
  # Retry configuration for transient failures
  max_retry_attempts: 5
  retry_initial_backoff_ms: 100
  retry_max_backoff_ms: 10000

# Additional client-side tuning recommendations for high load:
#
# 1. Increase file descriptor limits:
#    ulimit -n 100000
#
# 2. If using many concurrent connections, consider increasing local port range:
#    sudo sysctl -w net.ipv4.ip_local_port_range="1024 65535"
#
# 3. Enable TCP fast open:
#    sudo sysctl -w net.ipv4.tcp_fastopen=3
#
# 4. For macOS, increase socket buffer sizes:
#    sudo sysctl -w net.inet.tcp.sendspace=1048576
#    sudo sysctl -w net.inet.tcp.recvspace=1048576
